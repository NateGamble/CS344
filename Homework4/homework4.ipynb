{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\n",
    "I believe that \"deep\" neural nets are a breakthrough in the field of AI. Of course, it's hard to say if deep neural nets will be used many years in the future but many online platforms have adopted the use of these deep neural nets. Deep neural nets have proven their usefulness in so many areas, it's hard to think that they would turn out to be a bust like perceptrons. That's not to say I don't think they will be replaced. I expect that within a few decades we will have created something better (perhaps with quantum computing?) that will surpass the limits of deep neural nets. I don't think that will happen for a while though.\n",
    "\n",
    "## 2. \n",
    "![Back propagation part 1](./backpropagation1.jpg)\n",
    "![Back propagation part 2](./backpropagation2.jpg)  \n",
    "\n",
    "## 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                51232     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 89,130\n",
      "Trainable params: 89,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Configure a convnet with 2 layers of convolutions and max pooling.\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Add layers to flatten the 2D image and then do a 10-way classification.\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 27s 444us/step - loss: 0.4820 - accuracy: 0.8248\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 26s 435us/step - loss: 0.3115 - accuracy: 0.8875\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.2710 - accuracy: 0.9028\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 26s 436us/step - loss: 0.2446 - accuracy: 0.9125\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 26s 435us/step - loss: 0.2274 - accuracy: 0.9179\n",
      "10000/10000 [==============================] - 1s 126us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29500829927921296, 0.8938000202178955]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=32) #.88 with batch size 64, .89 with batch 32\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0.29500829927921296, 0.8938000202178955]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
